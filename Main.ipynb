{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21e1a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "from io import StringIO\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e18e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "if not os.path.exists(\"data\"):    ### Création d'un dossier data et de sous dossiers s'ils n'existent ###\n",
    "    os.makedirs(\"data\")           ### pas encore afin de stocker les données de chaque actif et       ###\n",
    "    os.makedirs(\"data/history\")   ### indices ainsi que la dernière fois que le programme a été lancé ###  \n",
    "    os.makedirs(\"data/data\")\n",
    "if not os.path.exists(\"data/history/sp500.txt\"):\n",
    "    with open(\"data/history/sp500.txt\",\"w\") as sp:\n",
    "        initialisation = str(int(pd.to_datetime(\"2000-01-01\")))\n",
    "        sp.write(initialisation)\n",
    "with open(\"data/history/sp500.txt\",\"r\") as sp:\n",
    "    row = sp.readlines()\n",
    "    last_line = int(row[-1].strip())\n",
    "if last_line//86400 != start_time//86400:                 ### On actualise les données via l'API Yahoo Finance ###\n",
    "    url = \"https://stockanalysis.com/list/sp-500-stocks/\" ### si la dernière fois que le programme à été lancé ###\n",
    "    headers = {\"user-agent\":\"Mozilla/5.0\"}                ### était un jour antérieur à aujourd'hui            ###\n",
    "    reponse = requests.get(url, headers=headers)\n",
    "    tickers = pd.read_html(StringIO(reponse.text))\n",
    "    tickers = tickers[0][\"Symbol\"]\n",
    "    tickers = tickers.to_list()\n",
    "    if \"GOOG\" in tickers:                                     ### Sur le site où on récupère les 500 tickers des actions ### \n",
    "        tickers.remove(\"GOOG\")                                ### qui composent le S&P500 GOOGLE est présent 2 fois      ### \n",
    "    tickers = [ticker.replace(\".\",\"-\") for ticker in tickers] \n",
    "    sp_data = yf.download(tickers,period=\"3mo\",interval=\"1d\")[[\"Open\",\"Close\"]]\n",
    "    sp_indice_data = yf.download(\"ES=F\", period=\"3mo\",interval=\"1d\")[[\"Open\",\"Close\"]]\n",
    "    sp_data.to_csv(\"data/data/sp_data.csv\")                   ### Enregistrement des données en csv pour ne pas avoir à  ### \n",
    "    sp_indice_data.to_csv(\"data/data/sp_indice_data.csv\")     ### les retélécherger plusieurs fois par jour              ###\n",
    "    print(\"Données actualisées depuis Yfinance\")\n",
    "else:\n",
    "    sp_data = pd.read_csv(\"data/data/sp_data.csv\")                ### Dans le cas où la dernière fois qu'on à lancé le   ###\n",
    "    sp_indice_data = pd.read_csv(\"data/data/sp_indice_data.csv\")  ### programme est dans la même journée qu'aujourd'hui, ###\n",
    "                                                                  ### on importe depuis le dossier data/data             ###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
